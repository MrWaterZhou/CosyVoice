from vllm import LLM, SamplingParams
import json
import os
import re
import torch
import numpy as np
from transformers import AutoTokenizer

pattern = re.compile(r"<\|speech-(\d+)\|>")


class OfflineInference:
    def __init__(self, model_path):
        self.bias = torch.load(os.path.join(model_path, 'bias.tensor')).to(torch.bfloat16)
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)

        def process_token(token_ids, logits):
            logits = logits + self.bias
            return logits

        stop = ["<|cos_eos|>"]
        tensor_parallel_size = 1
        max_tokens = 4096
        self.sampling_params = SamplingParams(temperature=0.0, best_of=1, stop=stop,
                                              max_tokens=max_tokens, repetition_penalty=1.3, n=1,
                                              logits_processors=[process_token])
        self.model = LLM(model=model_path,
                         tokenizer=model_path,
                         trust_remote_code=True,
                         tensor_parallel_size=tensor_parallel_size,
                         dtype='bfloat16',
                         max_model_len=max_tokens,
                         )

    def batch_infer(self, text_ids_list, prompt_speech_token_list):
        prompts = [[151936] + text_ids + [151937] + [x + 151938 for x in prompt_speech_token] for
                   text_ids, prompt_speech_token in
                   zip(text_ids_list, prompt_speech_token_list)]
        prompts = self.tokenizer.batch_decode(prompts, skip_special_tokens=False)

        outputs = self.model.generate(prompts, sampling_params=self.sampling_params)
        results = []
        for output in outputs:
            generated_text = output.outputs[0].text
            snac_tokens = pattern.findall(generated_text)
            snac_tokens = [int(x) for x in snac_tokens]
            results.append(snac_tokens)
        return results


if __name__ == '__main__':
    model = OfflineInference('pretrained_models/CosyVoice2-0.5B/merged')
    text_ids_list = [[32664, 1773, 77288, 35946, 99680, 99408, 21894, 16530, 18493,
                      99587, 1773, 99517, 39165, 13343, 31235, 18493, 99587, 9370,
                      29826, 99261, 3837, 80158, 20412, 18830, 14777, 35727, 35946,
                      99962, 30440, 23031, 99372, 99838, 3837, 60894, 33447, 103086,
                      103086, 99865, 99865, 29490, 99227, 14777, 82224, 99838, 99748,
                      107519, 99517, 1773, 35946, 99962, 39165, 7948, 74763, 20412,
                      43288, 81596, 99590, 50511, 99517, 9370, 1773, 50009, 26939,
                      52801, 97815, 45181, 99427, 23384, 101400, 36407, 9370, 21287,
                      8903, 99748, 52853, 3837, 99212, 69442, 36589, 47815, 9370,
                      99851, 99370, 57218, 99194, 99194, 9370, 100549, 99477, 99258,
                      35946, 63109, 15946, 99356, 99333, 34187, 100475, 100576, 9370,
                      99234, 99350, 3837, 48738, 36629, 29524, 99232, 99261, 99791,
                      103412, 53222, 1773]]
    prompt_speech_token_list = [[1573, 2166, 138, 5096, 398, 35, 733, 733, 732, 1704, 2112, 2112,
                                 4299, 4299, 4299, 4299, 4299, 4299, 2112, 1704, 3645, 3645, 5832, 5859,
                                 3675, 3648, 3645, 3645, 3645, 1458, 2112, 4299, 4299, 2166, 63, 4484,
                                 4979, 3590, 584, 578, 1884, 1793, 5914, 1092, 183, 4519, 6501, 3584,
                                 668, 2148, 1443, 1280, 6378, 3465, 4487, 5188, 3002, 524, 573, 570,
                                 1456, 1367, 598, 1300, 2112, 4299, 4299, 4299, 4299, 4299, 4299, 4299,
                                 4299, 4299, 4299, 4299, 4299, 4299, 4299, 4299, 4299, 4299, 4299, 4299,
                                 4299, 4299, 2112, 1842, 2916, 5113, 225, 297, 4457, 5071, 6448, 5949,
                                 6048, 1535, 882, 5001, 2421, 4597, 4523, 1284, 4923, 5, 326, 2760,
                                 2841, 2912, 1044, 74, 3047, 6021, 6291, 127, 920, 3080, 1892, 1649,
                                 1657, 1620, 4299, 4299, 4299, 4299, 4299, 4299, 4299, 4299, 4299, 4299,
                                 4299, 4299, 4299, 2112, 2463, 4839, 3157, 6311, 5896, 6057, 3077, 3481,
                                 404, 1433, 2093, 1616, 4940, 960, 57, 2760, 4633, 4487, 2884, 3590,
                                 575, 1434, 2163, 3728, 5834, 468, 489, 405, 3012, 5102, 5075, 647,
                                 877, 1611, 404, 1052, 523, 2760, 2841, 2775, 4682, 4448, 3178, 2028,
                                 3972, 2112, 4299, 4299, 4299, 2031, 3891, 5832, 5832, 5835, 5859, 5862,
                                 5943, 3729, 1542, 1542, 1785, 2112, 2028, 1657, 929, 5589, 5035, 2897,
                                 2717, 4944, 2779, 5048, 5776, 4875, 5776, 5048, 6040, 3720, 4849, 4570,
                                 3151, 4534, 62, 873, 306, 1188, 1440, 5996, 2366, 2321, 942, 6051,
                                 810, 1217, 503, 2841, 2766, 4745, 5986, 2240, 5100, 1203, 546, 6055,
                                 6027, 1699, 1610, 1920, 297, 2926, 2918, 2189, 3160, 973, 1944, 2028,
                                 4299, 4299, 4299, 4299, 4299, 4299, 4299, 4299, 4299, 4299, 4299, 4299,
                                 4299, 4299, 4299, 4299, 4218, 2122, 1457, 626, 1443, 685, 3890, 4483,
                                 1761, 2224, 4942, 2799, 6177, 2699, 4670, 4830, 2582, 1763, 1516, 6048,
                                 3072, 3150, 5976, 4600, 2128, 2045, 1587, 64, 3650, 5915, 4742, 2699,
                                 134, 2125, 1278, 3888, 3646, 731, 784, 2004]]

    results = model.batch_infer(text_ids_list, prompt_speech_token_list)
    print(results)

    target = [36, 757, 1000, 1216, 2025, 2112, 4299, 4299, 4299, 2112, 4218, 3645, 5835, 5832, 5862, 5862, 5862, 3648,
              3648, 3648, 1461, 1788, 5940, 6049, 1170, 4843, 300, 4511, 2678, 4863, 5589, 3416, 575, 4601, 4615, 2576,
              707, 1044, 4998, 648, 593, 5206, 6289, 3401, 842, 1334, 6537, 6534, 2759, 4637, 4074, 4921, 2508, 4490,
              3718, 1466, 112, 306, 4523, 5211, 5319, 2314, 5311, 6043, 5960, 1586, 1613, 80, 1375, 1772, 2093, 2186,
              4373, 5831, 2915, 716, 610, 2758, 1300, 2110, 2112, 4299, 4299, 4299, 4299, 4299, 4299, 4218, 4299, 4218,
              4299, 4299, 4299, 4299, 4299, 4218, 2031, 3825, 748, 4570, 4616, 6426, 3528, 4754, 4481, 4886, 4912, 5100,
              5341, 3643, 2594, 32, 1038, 77, 1194, 4922, 2509, 5075, 6262, 5532, 4416, 4676, 4678, 1293, 3482, 6316,
              1859, 1130, 5887, 6049, 873, 5231, 5286, 5949, 5238, 4519, 3906, 4655, 883, 1758, 6300, 5826, 5098, 1457,
              4275, 6534, 6534, 2182, 1448, 719, 2906, 2798, 2677, 1216, 2025, 2112, 4299, 2031, 2028, 3888, 6075, 5859,
              3672, 3675, 1458, 1788, 5940, 3072, 4484, 4964, 2861, 596, 2996, 4512, 4678, 3239, 5290, 4318, 3789, 5825,
              5047, 2130, 6048, 3564, 4966, 5044, 6501, 2432, 38, 1747, 56, 1842, 2220, 2760, 530, 1642, 4314, 5074,
              159, 57, 884, 570, 2838, 4863, 5437, 5269, 2924, 122, 3719, 4042, 272, 514, 487, 1216, 1944, 2112, 4299,
              4299, 4299, 4299, 4299, 2112, 4218, 4218, 2112, 4299, 4218, 3165, 4758, 4516, 2580, 4571, 4943, 626, 2180,
              4122, 1937, 623, 635, 2780, 4964, 2695, 1303, 2032, 2112, 4299, 2112, 2109, 4122, 4124, 2831, 5028, 4947,
              4955, 5428, 5995, 3839, 1676, 2160, 1440, 2918, 187, 1887, 6054, 2393, 3650, 20, 4233, 6537, 4347, 2678,
              2674, 3402, 1216, 2109, 4299, 4299, 4299, 4299, 2112]
    print(target)
